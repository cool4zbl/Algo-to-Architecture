# Heatmap Design â€“ Module 01: Ingestion Layer

tags: #streaming / #event-driven / #rate-limiting / #geo-spatial

## Problem

We need to handle frequent, high-volume location updates from drivers using a mobile app. Each update contains GPS coordinates and a timestamp. These events must be collected reliably and made available for real-time and batch processing downstream.

## Input

Event Schema Design(LocationUpdateEvent):

```json
{
  "driver_id": "abc123",
  "lat": 52.378,
  "lon": 4.900,
  "timestamp": 1711490415
}

```
- Precision: optional rounding / geo-binning (e.g., GeoHash)	
- Timestamp: server-side or device-side?	
- Payload Size: consider compression / batching for mobile data limits

## Responsibilities

- Receive high-frequency GPS updates from thousands of drivers
- Ensure events are reliably ingested without loss or duplication
- Decouple frontend (driver app) from backend consumers
- Support horizontal scaling for ingestion pipeline

## Architecture

1. Driver App periodically pushes location updates via HTTP/gRPC to a Collector Service
2. Collector validates and formats the event
3. Collector asynchronously publishes events to a Kafka topic
4. Kafka serves as a buffer and fan-out point to downstream consumers

## Technologies

- Protocol: HTTP or gRPC
- Message Queue: Apache Kafka (or Google PubSub / AWS Kinesis)
- Message Format: JSON or Protobuf
- Optionally use load balancer or API gateway (e.g., NGINX, Envoy)

## Key Design Patterns (Ingestion Layer)

| Pattern                      | Purpose                                             |
|-----------------------------|-----------------------------------------------------|
| Queue-Based Load Leveling   | Decouple ingestion spikes from processing speed     |
| Competing Consumers         | Allow parallel consumer instances for scalability   |
| Idempotency                 | Ensure retry-safe event handling (deduplication)    |
| Rate Limiting / Throttling  | Protect system from overload due to rapid updates from rogue clients / bad GPS devices |

## Key Trade-off / Design Questions

- How frequently should drivers push updates (every 2â€“5 seconds)?
- How to control update frequency? (enforce client-side and server-side throttling)
- How to handle network failures or retries?
- Rea-time freshness expectations? (e.g. within 1-2 sec latency)
- Is ordering required per driver or globally?

## ğŸ§­ Design Tips / Personal Reflections
- Consider using geo-hashing or grid rounding for lat/lon to reduce payload size and improve aggregation efficiency.
- Collect metadata (device info, GPS accuracy) for quality control.
- Start simple with 1 Kafka topic and scale with partitioning strategy (e.g., by driver_id or geo region).
- æŠŠâ€œé«˜é¢‘è¡Œä¸ºâ€å…ˆæŠ½è±¡æˆâ€œæ ‡å‡†åŒ–äº‹ä»¶æµâ€ï¼Œè¿™æ˜¯ç³»ç»Ÿè®¾è®¡å…³é”®ç¬¬ä¸€æ­¥ï¼› 
- Kafka æ˜¯ä¸€ä¸ªå¤©ç„¶çš„â€œæµä¸­å°â€ï¼ˆstreaming bufferï¼‰ï¼Œå¾ˆé€‚åˆ decoupleï¼› 
- ä¸è¦æ€¥ç€åšèšåˆï¼Œå…ˆæŠŠ ingestion æµè®¾è®¡ cleanï¼Œåé¢æ‰èƒ½ scaleï¼› 
- è¿™ä¸€å±‚åšå¯¹äº†ï¼Œç³»ç»Ÿä¸‹é™å°±ç¨³äº†

## Next Steps (for future cards)

- [ ] Streaming Aggregator â†’ Real-time grid binning + sliding window
- [ ] Redis Materialized View + Cache Invalidation
- [ ] Query API (geo bounding box, map overlay)
- [ ] Cold Storage â†’ S3 + Batch ETL for trend analysis
